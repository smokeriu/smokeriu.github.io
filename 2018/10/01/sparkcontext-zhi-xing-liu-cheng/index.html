<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-material.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blog.ibuer.fun","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="前言其实这个也算是Spark任务提交的内容之一。Spark任务的关键就是构建DAG图，Action触发然后去解析DAG图，将Stage交给Executor处理，executor处理完成后返回结果。Spark程序都是以SparkContext为入口，触发Action算子后执行具体任务，这边也会顺着这条思路写下去。  部分源码为了方便阅读会进行精简或调整，与真实源码会略有不同。但整体思路是一样的。Sp">
<meta property="og:type" content="article">
<meta property="og:title" content="SparkContext执行流程">
<meta property="og:url" content="http://blog.ibuer.fun/2018/10/01/sparkcontext-zhi-xing-liu-cheng/index.html">
<meta property="og:site_name" content="Ssiu Blog">
<meta property="og:description" content="前言其实这个也算是Spark任务提交的内容之一。Spark任务的关键就是构建DAG图，Action触发然后去解析DAG图，将Stage交给Executor处理，executor处理完成后返回结果。Spark程序都是以SparkContext为入口，触发Action算子后执行具体任务，这边也会顺着这条思路写下去。  部分源码为了方便阅读会进行精简或调整，与真实源码会略有不同。但整体思路是一样的。Sp">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://my-blog-1259467560.cos.ap-chengdu.myqcloud.com/win/20200217224954.png">
<meta property="article:published_time" content="2018-09-30T16:45:50.000Z">
<meta property="article:modified_time" content="2020-02-17T15:21:27.856Z">
<meta property="article:author" content="Ssiu">
<meta property="article:tag" content="Spark">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://my-blog-1259467560.cos.ap-chengdu.myqcloud.com/win/20200217224954.png">

<link rel="canonical" href="http://blog.ibuer.fun/2018/10/01/sparkcontext-zhi-xing-liu-cheng/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>SparkContext执行流程 | Ssiu Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Ssiu Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://blog.ibuer.fun/2018/10/01/sparkcontext-zhi-xing-liu-cheng/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ssiu">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ssiu Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          SparkContext执行流程
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-10-01 00:45:50" itemprop="dateCreated datePublished" datetime="2018-10-01T00:45:50+08:00">2018-10-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-17 23:21:27" itemprop="dateModified" datetime="2020-02-17T23:21:27+08:00">2020-02-17</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>其实这个也算是Spark任务提交的内容之一。Spark任务的关键就是构建DAG图，Action触发然后去解析DAG图，将Stage交给Executor处理，executor处理完成后返回结果。<br>Spark程序都是以SparkContext为入口，触发Action算子后执行具体任务，这边也会顺着这条思路写下去。</p>
<blockquote>
<p>部分源码为了方便阅读会进行精简或调整，与真实源码会略有不同。但整体思路是一样的。<br>Spark版本参照最新的2.3.x<br>涉及模式主要介绍Yarn和Local</p>
</blockquote>
<h1 id="流程图概览"><a href="#流程图概览" class="headerlink" title="流程图概览"></a>流程图概览</h1><p><img src="https://my-blog-1259467560.cos.ap-chengdu.myqcloud.com/win/20200217224954.png" alt="流程图"><br>先看图，整个流程可以分成四个步骤，具体会在源码中有所展现：</p>
<ol>
<li>根据我们的各种算子生成DAG图</li>
<li>解析DAG图，拆分成Stage（Task集合）。将Task集合发往下一步。</li>
<li>Cluster Manager来发起任务，错误或落伍(比如说数据倾斜导致某一任务始终跑不完)，会进行重试。</li>
<li>将Task发往具体的Worker/Container执行。</li>
</ol>
<h2 id="1）获取SparkContext"><a href="#1）获取SparkContext" class="headerlink" title="1）获取SparkContext"></a>1）获取SparkContext</h2><p>在程序里我们会通过<code>new SparkContext(Conf)</code>来得到一个SparkContext实例，具体到SparkContext里，由于代码很多，这边主要的其实就是初始化三个变量：    </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SparkContext</span>(<span class="title">config</span>: <span class="title">SparkConf</span>) <span class="keyword">extends</span> <span class="title">Logging</span></span>&#123;</span><br><span class="line">	<span class="comment">// 初始化三个主要变量</span></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">var</span> _schedulerBackend: SchedulerBackend = _</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">var</span> _taskScheduler: TaskScheduler = _</span><br><span class="line">	<span class="meta">@volatile</span> <span class="keyword">private</span> <span class="keyword">var</span> _dagScheduler: DAGScheduler = _</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 之后会对上述三个变量进行初始化：</span></span><br><span class="line">	val (sched, ts) = SparkContext.createTaskScheduler(<span class="keyword">this</span>, master, deployMode)</span><br><span class="line">    _schedulerBackend = sched</span><br><span class="line">    _taskScheduler = ts</span><br><span class="line">    _dagScheduler = <span class="keyword">new</span> DAGScheduler(<span class="keyword">this</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里代码根据具体的master、deployMode来对<code>_schedulerBackend</code>和<code>_taskScheduler</code>进行初始化，同时还会初始化<code>_dagScheduler</code></p>
<h3 id="1-1）其中createTaskScheduler方法"><a href="#1-1）其中createTaskScheduler方法" class="headerlink" title="1.1）其中createTaskScheduler方法"></a>1.1）其中createTaskScheduler方法</h3><p>主要用来初始化<code>_schedulerBackend</code>和<code>_taskScheduler</code>，这里以local为例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">createTaskScheduler</span><span class="params">(..)</span></span>&#123;</span><br><span class="line">	master match &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="string">&quot;local&quot;</span> =&gt;</span><br><span class="line">        val scheduler = <span class="keyword">new</span> TaskSchedulerImpl(sc, MAX_LOCAL_TASK_FAILURES, isLocal = <span class="keyword">true</span>)</span><br><span class="line">        val backend = <span class="keyword">new</span> LocalSchedulerBackend(sc.getConf, scheduler, <span class="number">1</span>)</span><br><span class="line">        scheduler.initialize(backend)</span><br><span class="line">        (backend, scheduler)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过这段代码，我们可以知道，一个是<code>TaskSchedulerImpl</code>的实例，一个是<code>LocalSchedulerBackend</code>的实例。里面主要就是初始化一些参数内容。具体的方法在后续过程会使用到，这里不进行过多赘述。</p>
<h3 id="1-2）其中new-DAGScheduler-this-里"><a href="#1-2）其中new-DAGScheduler-this-里" class="headerlink" title="1.2）其中new DAGScheduler(this)里"></a>1.2）其中new DAGScheduler(this)里</h3><p>初始化时有两个关键点：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">DAGScheduler</span>(...)</span>&#123;</span><br><span class="line">	<span class="keyword">private</span>[spark] val eventProcessLoop = <span class="keyword">new</span> DAGSchedulerEventProcessLoop(<span class="keyword">this</span>)</span><br><span class="line">	taskScheduler.setDAGScheduler(<span class="keyword">this</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这边会生成一个事件队列<code>eventProcessLoop</code>，同时设置我们的<code>taskScheduler</code>。这些内容会在之后使用到。<br>至此，这个阶段SparkContext的主要任务已经基本完成：设置我们上面提到的三个参数。<br>接下来，就要等到Action算子触发实际的作业运行了。</p>
<h2 id="2）Action"><a href="#2）Action" class="headerlink" title="2）Action"></a>2）Action</h2><p>这里以Collect算子为例，里面会调用<code>runJob</code>这个方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">RDD</span>[<span class="title">T</span>: <span class="title">ClassTag</span>](...)</span>&#123;</span><br><span class="line">	<span class="function">def <span class="title">collect</span><span class="params">()</span>: Array[T] </span>= withScope &#123;</span><br><span class="line">    val results = sc.runJob(<span class="keyword">this</span>, (iter: Iterator[T]) =&gt; iter.toArray)</span><br><span class="line">    Array.concat(results: _*)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>里面点进去，实际会进行多次跳转，这边把中间过程进行省略，最后我们会来到：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SparkContext</span>(<span class="title">config</span>: <span class="title">SparkConf</span>) <span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">  def runJob[T, U: ClassTag](...)&#123;</span><br><span class="line">  	val callSite = getCallSite</span><br><span class="line">    val cleanedFunc = clean(func)</span><br><span class="line">  	<span class="comment">// 前面是一些参数初始化</span></span><br><span class="line">  	</span><br><span class="line">  	<span class="comment">// 核心，进入runJob。</span></span><br><span class="line">  	dagScheduler.runJob(rdd, cleanedFunc, partitions, callSite, resultHandler, localProperties.get)</span><br><span class="line">  	</span><br><span class="line">  	<span class="comment">// 其他处理</span></span><br><span class="line">    progressBar.foreach(_.finishAll())</span><br><span class="line">    rdd.doCheckpoint()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们这里主要需要关注<code>dagScheduler.runJob</code>方法，跟这个这个方法，我们来到了DAGScheduler：</p>
<h2 id="3）DAGScheduler"><a href="#3）DAGScheduler" class="headerlink" title="3）DAGScheduler"></a>3）DAGScheduler</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def runJob[T, U](...)&#123;</span><br><span class="line">	val start = System.nanoTime</span><br><span class="line">    val waiter = submitJob(rdd, func, partitions, callSite, resultHandler, properties)&#123;</span><br><span class="line">		eventProcessLoop.post(JobSubmitted(</span><br><span class="line">			jobId, rdd, func2, partitions.toArray, callSite, waiter,</span><br><span class="line">			SerializationUtils.clone(properties)))</span><br><span class="line">		waiter</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里我将两段代码进行了合并，runJob会调用<code>submitJob</code>方法，这个方法会返回一个<code>JobWaiter</code>对象，简单来说，就是将我们的Func、Rdd加入之前创建的<code>eventProcessLoop</code>。</p>
<h3 id="3-1）DAGSchedulerEventProcessLoop"><a href="#3-1）DAGSchedulerEventProcessLoop" class="headerlink" title="3.1）DAGSchedulerEventProcessLoop"></a>3.1）DAGSchedulerEventProcessLoop</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[scheduler] <span class="class"><span class="keyword">class</span> <span class="title">DAGSchedulerEventProcessLoop</span></span>&#123;</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	* The main event loop of the DAG scheduler.</span></span><br><span class="line"><span class="comment">	*/</span></span><br><span class="line">	<span class="function">override def <span class="title">onReceive</span><span class="params">(event: DAGSchedulerEvent)</span>: Unit </span>= &#123;..doOnReceive..&#125;</span><br><span class="line">	<span class="function"><span class="keyword">private</span> def <span class="title">doOnReceive</span><span class="params">(event: DAGSchedulerEvent)</span>: Unit </span>= event match &#123;</span><br><span class="line">		<span class="function"><span class="keyword">case</span> <span class="title">JobSubmitted</span><span class="params">(jobId, rdd, func, partitions, callSite, listener, properties)</span> </span>=&gt;</span><br><span class="line">      dagScheduler.handleJobSubmitted(jobId, rdd, func, partitions, callSite, listener, properties)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个类我同样进行了简化，实际上就是判断我们提交过来的是什么，然后指向对应的方法。</p>
<blockquote>
<p>这里我们是JobSubmitted。所以指向dagScheduler.handleJobSubmitted</p>
</blockquote>
<h3 id="3-2）handleJobSubmitted"><a href="#3-2）handleJobSubmitted" class="headerlink" title="3.2）handleJobSubmitted"></a>3.2）handleJobSubmitted</h3><p>实际上源码会有很多的try catch，这边进行部分简写方便阅读</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">handleJobSubmitted</span><span class="params">(...)</span></span>&#123;</span><br><span class="line">	<span class="keyword">var</span> finalStage: ResultStage = </span><br><span class="line">		createResultStage(finalRDD, func, partitions, jobId, callSite)</span><br><span class="line">	val job = <span class="keyword">new</span> ActiveJob(jobId, finalStage, callSite, listener, properties)</span><br><span class="line">	finalStage.setActiveJob(job)</span><br><span class="line">	submitStage(finalStage)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里首先会拿到最后一个Stage，并通过它生成running job。最终我们将finalStage提交。</p>
<blockquote>
<p>A running job in the DAGScheduler. Jobs can be of two types:<br>1）a result job, which computes a ResultStage to execute an action,<br>2）or a map-stage job, which computes the map outputs for a ShuffleMapStage before any downstream stages are submitted.</p>
</blockquote>
<h3 id="3-3）submitStage"><a href="#3-3）submitStage" class="headerlink" title="3.3）submitStage"></a>3.3）submitStage</h3><p>这个部分实际就承担了拆分Stage的职责，其实就是通过递归完成的，为了方便理解就直接搬源码了。大家可以结合提交的作业时打印的log看看。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">submitStage</span><span class="params">(stage: Stage)</span> </span>&#123;</span><br><span class="line">  val jobId = activeJobForStage(stage)</span><br><span class="line">  <span class="keyword">if</span> (jobId.isDefined) &#123;</span><br><span class="line">    logDebug(<span class="string">&quot;submitStage(&quot;</span> + stage + <span class="string">&quot;)&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> (!waitingStages(stage) &amp;&amp; !runningStages(stage) &amp;&amp; !failedStages(stage)) &#123;</span><br><span class="line">      val missing = getMissingParentStages(stage).sortBy(_.id)</span><br><span class="line">      logDebug(<span class="string">&quot;missing: &quot;</span> + missing)</span><br><span class="line">      <span class="keyword">if</span> (missing.isEmpty) &#123;</span><br><span class="line">        logInfo(<span class="string">&quot;Submitting &quot;</span> + stage + <span class="string">&quot; (&quot;</span> + stage.rdd + <span class="string">&quot;), which has no missing parents&quot;</span>)</span><br><span class="line">        submitMissingTasks(stage, jobId.get)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (parent &lt;- missing) &#123;</span><br><span class="line">          submitStage(parent)</span><br><span class="line">        &#125;</span><br><span class="line">        waitingStages += stage</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    abortStage(stage, <span class="string">&quot;No active job for stage &quot;</span> + stage.id, None)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>方法首先接收到的是finalStage，关键是<code>getMissingParentStages(stage)</code>，方法返回<code>List[Stage]</code>。这里能够得到尚未执行的ParentStage，并按照id排序。<br>所以这边的逻辑实际是：提交finalStage → 尚有父Stage没执行 → 提交父Stage，递归，直到所有父Stage都执行。<br>最终，对于每个Stage，底层都会来到<code>submitMissingTasks(stage, jobId.get)</code></p>
<h3 id="3-4）submitMissingTasks"><a href="#3-4）submitMissingTasks" class="headerlink" title="3.4）submitMissingTasks"></a>3.4）submitMissingTasks</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">submitMissingTasks</span><span class="params">(stage: Stage, jobId: Int)</span> </span>&#123;</span><br><span class="line">	<span class="comment">//..省略一些前置处理..</span></span><br><span class="line">	<span class="comment">//..主要就是将Stage包装成Tasks用来提交</span></span><br><span class="line">	val tasks: Seq[Task[_]] = <span class="keyword">try</span> &#123;</span><br><span class="line">		stage match &#123;</span><br><span class="line">        <span class="keyword">case</span> stage: ShuffleMapStage =&gt;</span><br><span class="line">          stage.pendingPartitions.clear()</span><br><span class="line">          partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">            &#123;...&#125;</span><br><span class="line">            <span class="keyword">new</span> ShuffleMapTask(...)</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">case</span> stage: ResultStage =&gt;</span><br><span class="line">          partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">            &#123;...&#125;</span><br><span class="line">            <span class="keyword">new</span> ResultTask(...)</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">//..提交tasks..//</span></span><br><span class="line">	<span class="keyword">if</span> (tasks.size &gt; <span class="number">0</span>) &#123;</span><br><span class="line">		taskScheduler.submitTasks(<span class="keyword">new</span> TaskSet(</span><br><span class="line">        	tasks.toArray, stage.id, stage.latestInfo.attemptNumber, jobId, properties))</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>调用<code>taskScheduler</code>的<code>submitTasks</code>方法进行task的提交，这段方法的用途注释已经说明，其实目的就是将Stage包装成Task集合。里面有大量的判断这边就忽略了。<br>其实刚刚也提到过，Task在内部被Spark分为中间的：ShuffleMap，以及最后的：Result。这个也对应的不同的Job。<br>代码跟着就来到了TasklScheduler</p>
<h2 id="4）TaskScheduler"><a href="#4）TaskScheduler" class="headerlink" title="4）TaskScheduler"></a>4）TaskScheduler</h2><p>实际上TaskScheduler是一个trait，通过之前的分析(初始化SparkContext)，我们可以知道实际上我们建立的是一个<code>TaskSchedulerImpl</code>对象，实际上Spark本身就实现了这么一个子类。这里直接定位到对应方法即可。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">TaskSchedulerImpl</span>(...)</span>&#123;</span><br><span class="line">	<span class="function">override def <span class="title">submitTasks</span><span class="params">(taskSet: TaskSet)</span> </span>&#123;</span><br><span class="line">	    val tasks = taskSet.tasks</span><br><span class="line">	    <span class="keyword">this</span>.<span class="keyword">synchronized</span> &#123;</span><br><span class="line">	    	val manager = createTaskSetManager(taskSet, maxTaskFailures)</span><br><span class="line">	    	val stage = taskSet.stageId</span><br><span class="line">	    	val stageTaskSets =</span><br><span class="line">        		taskSetsByStageIdAndAttempt.getOrElseUpdate(stage, <span class="keyword">new</span> HashMap[Int, TaskSetManager])</span><br><span class="line">        		</span><br><span class="line">        	<span class="comment">// 建立taskset与manager 的对应关系</span></span><br><span class="line">			stageTaskSets(taskSet.stageAttemptId) = manager</span><br><span class="line">			</span><br><span class="line">			<span class="comment">// TaskSetManager会被放入调度池中。</span></span><br><span class="line">			schedulableBuilder.addTaskSetManager(manager, manager.taskSet.properties)</span><br><span class="line">	    &#125;</span><br><span class="line">	    <span class="comment">// 为tasks分配资源，调度任务</span></span><br><span class="line">	    backend.reviveOffers()</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里会初始化一个Manager对Tasks进行管理，在最开始也说过，对于失败或者落队的任务Manager会进行重试，并与上一级交互执行情况。不过对于本文章讨论的流程来说，这部分实际上最重要的，就是将Task提交到具体的Executor。也就是<code>backend.reviveOffers()</code>。<br>对于不同的任务，SchedulerBackend有两个实现类：</p>
<ul>
<li>CoarseGrainedSchedulerBackend</li>
<li>LocalSchedulerBackend。</li>
</ul>
<p>这边就以CoarseGrainedSchedulerBackend为例进行继续讲解。他们的区别从命名其实就能猜到。</p>
<h3 id="4-1）CoarseGrainedSchedulerBackend"><a href="#4-1）CoarseGrainedSchedulerBackend" class="headerlink" title="4.1）CoarseGrainedSchedulerBackend"></a>4.1）CoarseGrainedSchedulerBackend</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">CoarseGrainedSchedulerBackend</span>(<span class="title">scheduler</span>: <span class="title">TaskSchedulerImpl</span>, <span class="title">val</span> <span class="title">rpcEnv</span>: <span class="title">RpcEnv</span>)</span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">ExecutorAllocationClient</span> <span class="title">with</span> <span class="title">SchedulerBackend</span> <span class="title">with</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">  </span><br><span class="line">	<span class="function">override def <span class="title">reviveOffers</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		driverEndpoint.send(ReviveOffers)</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// driverEndpoint的初始化，都在CoarseGrainedSchedulerBackend类里。</span></span><br><span class="line">	<span class="function">override def <span class="title">start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    	val properties = <span class="keyword">new</span> ArrayBuffer[(String, String)]</span><br><span class="line">    	driverEndpoint = createDriverEndpointRef(properties)</span><br><span class="line">    &#125;	</span><br><span class="line">	<span class="function"><span class="keyword">protected</span> def <span class="title">createDriverEndpointRef</span><span class="params">(...)</span>: RpcEndpointRef </span>= &#123;</span><br><span class="line">		rpcEnv.setupEndpoint(ENDPOINT_NAME, createDriverEndpoint(properties))</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="function"><span class="keyword">protected</span> def <span class="title">createDriverEndpoint</span><span class="params">(properties: Seq[(String, String)</span>]): DriverEndpoint </span>= &#123;</span><br><span class="line">    	<span class="keyword">new</span> DriverEndpoint(rpcEnv, properties)</span><br><span class="line">  	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由于<code>reviveOffers</code>方法里会使用到<code>driverEndpoint</code>，这边一并将他的初始化源码附上。通过源码我们也能注意到，这里主要是<code>DriverEndpoint</code>完成了实际工作，毕竟，我们要发送ReviveOffers事件，这个事件从哪来的？进入DriverEndPoint一探究竟。</p>
<blockquote>
<p>DriverEndpoint是CoarseGrainedSchedulerBackend的一个内部类。</p>
</blockquote>
<h3 id="4-2）DriverEndpoint"><a href="#4-2）DriverEndpoint" class="headerlink" title="4.2）DriverEndpoint"></a>4.2）DriverEndpoint</h3><p>实际上，driverEndpoint.send(ReviveOffers)会触发DriverEndPoint的makeOffers方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DriverEndpoint</span>(...) <span class="keyword">extends</span> <span class="title">ThreadSafeRpcEndpoint</span> <span class="title">with</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">	override def receive: PartialFunction[Any, Unit] = &#123;</span><br><span class="line">		<span class="keyword">case</span> ReviveOffers =&gt;</span><br><span class="line">        	makeOffers()</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用makeOffers</span></span><br><span class="line">	<span class="function"><span class="keyword">private</span> def <span class="title">makeOffers</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="comment">// 主要是找出要在哪些Worker上启动哪些task。</span></span><br><span class="line">		val taskDescs = withLock &#123;</span><br><span class="line">			scheduler.resourceOffers(workOffers)</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> (!taskDescs.isEmpty) &#123;</span><br><span class="line">        	launchTasks(taskDescs)</span><br><span class="line">      	&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>resourceOffers返回的是Seq[Seq[TaskDescription]] 类型，主要用途是找出要在哪些Worker上启动哪些task。最后调用launchTasks(taskDescs)。</p>
<h3 id="4-3）launchTasks"><a href="#4-3）launchTasks" class="headerlink" title="4.3）launchTasks"></a>4.3）launchTasks</h3><p>主要完成序列化，发送任务的工作：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">launchTasks</span><span class="params">(tasks: Seq[Seq[TaskDescription]])</span> </span>&#123;</span><br><span class="line">	<span class="keyword">for</span> (task &lt;- tasks.flatten) &#123;</span><br><span class="line">		<span class="comment">// 序列化Task</span></span><br><span class="line">        val serializedTask = TaskDescription.encode(task)</span><br><span class="line">        <span class="comment">// 省略一些判断</span></span><br><span class="line">        <span class="comment">// 发送序列化后的Task</span></span><br><span class="line">        executorData.executorEndpoint.send(LaunchTask(<span class="keyword">new</span> SerializableBuffer(serializedTask)))</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>至此，任务已经发往了Executor</p>
<h2 id="5）Executor"><a href="#5）Executor" class="headerlink" title="5）Executor"></a>5）Executor</h2><p>先找到：CoarseGrainedExecutorBackend.scala</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">CoarseGrainedExecutorBackend</span>(...)</span></span><br><span class="line"><span class="class">	<span class="keyword">extends</span> <span class="title">ThreadSafeRpcEndpoint</span> <span class="title">with</span> <span class="title">ExecutorBackend</span> <span class="title">with</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	override def receive: PartialFunction[Any, Unit] = &#123;</span><br><span class="line">		<span class="function"><span class="keyword">case</span> <span class="title">LaunchTask</span><span class="params">(data)</span> </span>=&gt;</span><br><span class="line">			val taskDesc = TaskDescription.decode(data.value)</span><br><span class="line">    	    logInfo(<span class="string">&quot;Got assigned task &quot;</span> + taskDesc.taskId)</span><br><span class="line">        	executor.launchTask(<span class="keyword">this</span>, taskDesc)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这部分代码完成：接收，生成Executor，在Executor上launchTask的任务。代码进入到Executor.scala</p>
<h3 id="5-1）Executor-scala"><a href="#5-1）Executor-scala" class="headerlink" title="5.1）Executor.scala"></a>5.1）Executor.scala</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">Executor</span>(...)</span>&#123;</span><br><span class="line">	<span class="keyword">private</span> val runningTasks = <span class="keyword">new</span> ConcurrentHashMap[Long, TaskRunner]</span><br><span class="line">  	<span class="function">def <span class="title">launchTask</span><span class="params">(context: ExecutorBackend, taskDescription: TaskDescription)</span>: Unit </span>= &#123;</span><br><span class="line">    	val tr = <span class="keyword">new</span> TaskRunner(context, taskDescription)</span><br><span class="line">    	runningTasks.put(taskDescription.taskId, tr)</span><br><span class="line">    	threadPool.execute(tr)</span><br><span class="line">  	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里就是将我们的Task新起一个TaskRunner，并加入了线程池，所以具体的处理需要进入TaskRunner里。</p>
<h3 id="5-2）TaskRunner"><a href="#5-2）TaskRunner" class="headerlink" title="5.2）TaskRunner"></a>5.2）TaskRunner</h3><p>这是一个继承了Runnable的线程，所以我们直接找到run方法，其实主要干了三件事：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TaskRunner</span>(...) <span class="keyword">extends</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">	<span class="function">override def <span class="title">run</span><span class="params">()</span>: Unit </span>= &#123;</span><br><span class="line">	<span class="comment">// 反序列化</span></span><br><span class="line">	    Executor.taskDeserializationProps.set(taskDescription.properties)</span><br><span class="line">        updateDependencies(taskDescription.addedFiles, taskDescription.addedJars)</span><br><span class="line">        task = ser.deserialize[Task[Any]](</span><br><span class="line">          taskDescription.serializedTask, Thread.currentThread.getContextClassLoader)</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 运行我们的任务，得到结果</span></span><br><span class="line">		val value = Utils.tryWithSafeFinally &#123;</span><br><span class="line">			task.run(</span><br><span class="line">        		taskAttemptId = taskId,</span><br><span class="line">        		attemptNumber = taskDescription.attemptNumber,</span><br><span class="line">        		metricsSystem = env.metricsSystem)</span><br><span class="line">        &#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 包装结果，序列化，并发回。</span></span><br><span class="line">	val valueBytes = resultSer.serialize(value)</span><br><span class="line">	val directResult = <span class="keyword">new</span> DirectTaskResult(valueBytes, accumUpdates)</span><br><span class="line">	val serializedDirectResult = ser.serialize(directResult)</span><br><span class="line">	val serializedResult: ByteBuffer = &#123;...serializedDirectResult...&#125;</span><br><span class="line">	execBackend.statusUpdate(taskId, TaskState.FINISHED, serializedResult)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>基本上到这里，整个执行流程就说完了。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol>
<li>SparkContext<br> 1）根据提交的master类型，deploy类型等，生成TaskScheduler、DAGScheduler、 SchedulerBackend<br> 2）解析程序的业务逻辑：数据源 → trans → action<br> 3）触发Action，就到了DAGScheduler </li>
<li>DAGScheduler<br>1）runJob方法，最终目的就是拆分Stage<br>2）拆分方式是：先提交finalStage，如果尚有父Stage未提交，则会触发拆分。根据shuﬀle来 拆分。<br>3）总的来说，会一直递归，直到最父的Stage提交。最终才会提交finalStage 每次提交Stage，最终就会来到taskScheduler.submitTasks(new TaskSet) </li>
<li>TaskScheduler<br> 1）将接收到的Stage封装成TaskSet。使用submitTasks(taskSet: TaskSet)提交。<br> 2）将每个Task拿出来，通过TaskDescription.encode(task)序列化，用于网络传输。<br> 3）通过executorData.executorEndpoint.send将任务发往Executor </li>
<li>Executor<br> 1）receive方法接收发过来的Task。<br> 2）最终的处理逻辑在TaskRunner里。 <pre><code> 2.1）反序列化。task = ser.deserialize 执行func，
 2.2）返回结果。val value = Utils.tryWithSafeFinally &#123; task.run() &#125;
 2.3）将结果序列化。val serializedResult = serializedDirectResult 将结果发回。execBackend.statusUpdate
</code></pre>
</li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Spark/" rel="tag"># Spark</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2018/09/30/spark-ren-wu-ti-jiao-liu-cheng/" rel="prev" title="Spark任务提交流程">
      <i class="fa fa-chevron-left"></i> Spark任务提交流程
    </a></div>
      <div class="post-nav-item">
    <a href="/2018/12/31/spark-zhong-de-chuang-kou-han-shu-shi-yong/" rel="next" title="Spark中的窗口函数使用">
      Spark中的窗口函数使用 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B5%81%E7%A8%8B%E5%9B%BE%E6%A6%82%E8%A7%88"><span class="nav-number">2.</span> <span class="nav-text">流程图概览</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1%EF%BC%89%E8%8E%B7%E5%8F%96SparkContext"><span class="nav-number">2.1.</span> <span class="nav-text">1）获取SparkContext</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1%EF%BC%89%E5%85%B6%E4%B8%ADcreateTaskScheduler%E6%96%B9%E6%B3%95"><span class="nav-number">2.1.1.</span> <span class="nav-text">1.1）其中createTaskScheduler方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2%EF%BC%89%E5%85%B6%E4%B8%ADnew-DAGScheduler-this-%E9%87%8C"><span class="nav-number">2.1.2.</span> <span class="nav-text">1.2）其中new DAGScheduler(this)里</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2%EF%BC%89Action"><span class="nav-number">2.2.</span> <span class="nav-text">2）Action</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3%EF%BC%89DAGScheduler"><span class="nav-number">2.3.</span> <span class="nav-text">3）DAGScheduler</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1%EF%BC%89DAGSchedulerEventProcessLoop"><span class="nav-number">2.3.1.</span> <span class="nav-text">3.1）DAGSchedulerEventProcessLoop</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2%EF%BC%89handleJobSubmitted"><span class="nav-number">2.3.2.</span> <span class="nav-text">3.2）handleJobSubmitted</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3%EF%BC%89submitStage"><span class="nav-number">2.3.3.</span> <span class="nav-text">3.3）submitStage</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4%EF%BC%89submitMissingTasks"><span class="nav-number">2.3.4.</span> <span class="nav-text">3.4）submitMissingTasks</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4%EF%BC%89TaskScheduler"><span class="nav-number">2.4.</span> <span class="nav-text">4）TaskScheduler</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1%EF%BC%89CoarseGrainedSchedulerBackend"><span class="nav-number">2.4.1.</span> <span class="nav-text">4.1）CoarseGrainedSchedulerBackend</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2%EF%BC%89DriverEndpoint"><span class="nav-number">2.4.2.</span> <span class="nav-text">4.2）DriverEndpoint</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3%EF%BC%89launchTasks"><span class="nav-number">2.4.3.</span> <span class="nav-text">4.3）launchTasks</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5%EF%BC%89Executor"><span class="nav-number">2.5.</span> <span class="nav-text">5）Executor</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1%EF%BC%89Executor-scala"><span class="nav-number">2.5.1.</span> <span class="nav-text">5.1）Executor.scala</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2%EF%BC%89TaskRunner"><span class="nav-number">2.5.2.</span> <span class="nav-text">5.2）TaskRunner</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">3.</span> <span class="nav-text">总结</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Ssiu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">66</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">21</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ssiu</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false}});</script></body>
</html>
